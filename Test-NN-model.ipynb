{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import copy\n",
    "from scipy.signal import savgol_filter\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ./models/3-layers-64-32-16/model_64.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     model[i] \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/saving/save.py:206\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    205\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(filepath_str, \u001b[38;5;28mcompile\u001b[39m, options)\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at ./models/3-layers-64-32-16/model_64.h5"
     ]
    }
   ],
   "source": [
    "model_folder = './models/3-layers-64-32-16/'\n",
    "\n",
    "model = {}\n",
    "\n",
    "for i in range(1,100):\n",
    "    model[i] = keras.models.load_model(model_folder+'model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['046_CDF_survey.csv', '025_CDF_survey.csv', '048_CDF_survey.csv', '144_CDF_survey.csv', '021_CDF_survey.csv', '034_CDF_survey.csv', '137_CDF_survey.csv', '045_CDF_survey.csv', '154_CDF_survey.csv', '139_CDF_survey.csv', '001_CDF_survey.csv', '102_CDF_survey.csv', '110_CDF_survey.csv', '088_CDF_survey.csv', '013_CDF_survey.csv', '081_CDF_survey.csv', '012_CDF_survey.csv', '000_CDF_survey.csv', '017_CDF_survey.csv', '083_CDF_survey.csv', '004_CDF_survey.csv', '082_CDF_survey.csv', '072_CDF_survey.csv', '085_CDF_survey.csv']\n"
     ]
    }
   ],
   "source": [
    "output_folder = '3-layers-64-32-16'\n",
    "\n",
    "data_directory = './test_data/'\n",
    "\n",
    "os.chdir(data_directory)\n",
    "data_files = glob('*CDF_survey.csv')\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_folder)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "output_directory = data_directory + output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.linspace(1,99,99,dtype=int)\n",
    "quantile_names = [str(ic) for ic in c]\n",
    "\n",
    "gs = np.linspace(1,11,11,dtype=int)\n",
    "g_names = ['g'+str(i) for i in gs]\n",
    "\n",
    "column_names = ['g']+quantile_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "046_CDF_survey.csv  completed.\n",
      "025_CDF_survey.csv  completed.\n",
      "048_CDF_survey.csv  completed.\n",
      "144_CDF_survey.csv  completed.\n",
      "021_CDF_survey.csv  completed.\n",
      "034_CDF_survey.csv  completed.\n",
      "137_CDF_survey.csv  completed.\n",
      "045_CDF_survey.csv  completed.\n",
      "154_CDF_survey.csv  completed.\n",
      "139_CDF_survey.csv  completed.\n",
      "001_CDF_survey.csv  completed.\n",
      "102_CDF_survey.csv  completed.\n",
      "110_CDF_survey.csv  completed.\n",
      "088_CDF_survey.csv  completed.\n",
      "013_CDF_survey.csv  completed.\n",
      "081_CDF_survey.csv  completed.\n",
      "012_CDF_survey.csv  completed.\n",
      "000_CDF_survey.csv  completed.\n",
      "017_CDF_survey.csv  completed.\n",
      "083_CDF_survey.csv  completed.\n",
      "004_CDF_survey.csv  completed.\n",
      "082_CDF_survey.csv  completed.\n",
      "072_CDF_survey.csv  completed.\n",
      "085_CDF_survey.csv  completed.\n"
     ]
    }
   ],
   "source": [
    "for df in data_files:\n",
    "#for df in ['000_CDF_survey.csv']:\n",
    "    a = pd.read_csv(data_directory+df,header=None).to_numpy()\n",
    "\n",
    "    concs = np.zeros(shape=(a.shape[0],1))\n",
    "    concs[:,0] = a[:,0]\n",
    "\n",
    "    response_labels = np.zeros(shape=(a.shape[0],a.shape[0]))\n",
    "\n",
    "    for j in range(0,a.shape[0]):\n",
    "        response_labels[j,:] = a[:,1]\n",
    "\n",
    "    #this_array = np.concatenate((concs,response_labels,a[:,1:]),axis=1)\n",
    "    mean_array = np.zeros(shape=(a[:,1].shape[0],1))\n",
    "    mean_array[:,0] = a[:,1]\n",
    "    this_array = np.concatenate((mean_array,a[:,3:-1]),axis=1)\n",
    "    #this_array = np.concatenate((concs,a[:,1:]),axis=1)\n",
    "    #print(this_array.shape)\n",
    "\n",
    "    test_data = pd.DataFrame(this_array,index=[i for i in range(a.shape[0])],columns=column_names)\n",
    "    new_data = copy.deepcopy(test_data)\n",
    "    test_labels = {}\n",
    "\n",
    "    for i in range(1,this_array.shape[1]):\n",
    "        #print(column_names[i])\n",
    "        if i==2:\n",
    "            test_labels[column_names[i]] = test_data.pop(column_names[i])\n",
    "        else:\n",
    "            test_data.pop(column_names[i])\n",
    "            \n",
    "    #model_folder = '/Users/sns9/Research/IMS_project/CytometryData/PredictDispersion/model64/'\n",
    "\n",
    "    for i in range(1,100):\n",
    "        #model = keras.models.load_model(model_folder+'model_'+str(i)+'.h5')\n",
    "\n",
    "        test_predictions = model[i].predict(test_data).flatten()\n",
    "\n",
    "        new_data[str(i)] = np.maximum(test_predictions,0.0)\n",
    "        \n",
    "        if i>1:\n",
    "            test_data[str(i)] = test_data[str(i-1)] + np.maximum(test_predictions,0.0)\n",
    "        else:\n",
    "            test_data[str(i)] = np.maximum(test_predictions,0.0)\n",
    "\n",
    "        #final_data = np.zeros(shape=test_predictions.shape)\n",
    "\n",
    "        \"\"\"if i>0:\n",
    "            for k in range(0,final_data.shape[0]):\n",
    "                v1 = test_predictions[k]\n",
    "                v2 = new_data[str(i-1)][k]\n",
    "                #print(v1,v2)\n",
    "                final_data[k] = max(v1,v2)\n",
    "\n",
    "            new_data[str(i)] = final_data\n",
    "\n",
    "            test_data[str(i)] = final_data\n",
    "        else:\n",
    "            new_data[str(i)] = test_predictions\n",
    "\n",
    "            test_data[str(i)] = test_predictions\n",
    "        \"\"\"\n",
    "\n",
    "    print(df,' completed.')\n",
    "    \n",
    "    #for gn in g_names:\n",
    "    #    new_data.pop(gn)\n",
    "        \n",
    "    for iq in range(1,len(quantile_names)):\n",
    "        new_data[quantile_names[iq]] += new_data[quantile_names[iq-1]]\n",
    "        \n",
    "    new_data.to_csv(output_directory+'/new_'+df,index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = pd.read_csv(data_file,header=None).to_numpy()\n",
    "\n",
    "concs = np.zeros(shape=(a.shape[0],1))\n",
    "concs[:,0] = a[:,0]\n",
    "\n",
    "response_labels = np.zeros(shape=(a.shape[0],a.shape[0]))\n",
    "\n",
    "for j in range(0,a.shape[0]):\n",
    "    response_labels[j,:] = a[:,1]\n",
    "    \n",
    "this_array = np.concatenate((concs,response_labels,a[:,1:]),axis=1)\n",
    "#print(this_array.shape)\n",
    "\n",
    "test_data = pd.DataFrame(this_array,index=[i for i in range(a.shape[0])],columns=column_names)\n",
    "new_data = copy.deepcopy(test_data)\n",
    "test_labels = {}\n",
    "\n",
    "for i in range(13,this_array.shape[1]):\n",
    "    #print(column_names[i])\n",
    "    if i==2:\n",
    "        test_labels[column_names[i]] = test_data.pop(column_names[i])\n",
    "    else:\n",
    "        test_data.pop(column_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_folder = '/Users/sns9/Research/IMS_project/CytometryData/PredictDispersion/model64/'\n",
    "\n",
    "for i in range(0,101):\n",
    "    model = keras.models.load_model(model_folder+'model_'+str(i)+'.h5')\n",
    "    \n",
    "    test_predictions = model.predict(test_data).flatten()\n",
    "    \n",
    "    new_data[str(i)] = test_predictions\n",
    "    \n",
    "    test_data[str(i)] = test_predictions\n",
    "    \n",
    "    final_data = np.zeros(shape=test_predictions.shape)\n",
    "    \n",
    "    \"\"\"if i>0:\n",
    "        for k in range(0,final_data.shape[0]):\n",
    "            v1 = test_predictions[k]\n",
    "            v2 = new_data[str(i-1)][k]\n",
    "            #print(v1,v2)\n",
    "            final_data[k] = max(v1,v2)\n",
    "            \n",
    "        new_data[str(i)] = final_data\n",
    "    \n",
    "        test_data[str(i)] = final_data\n",
    "    else:\n",
    "        new_data[str(i)] = test_predictions\n",
    "    \n",
    "        test_data[str(i)] = test_predictions\n",
    "    \"\"\"\n",
    "    \n",
    "print(df,' completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for gn in g_names:\n",
    "    new_data.pop(gn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for iq in range(1,len(quantile_names)):\n",
    "    #print(quantile_names[iq-1],quantile_names[iq])\n",
    "    new_data[quantile_names[iq]] += new_data[quantile_names[iq-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_data.to_csv('new_'+data_file,index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in new_data.index:\n",
    "    data_tag = new_data.loc[i].to_numpy()[:2]\n",
    "    data = new_data.loc[i].to_numpy()[2:]\n",
    "    smoothed_data = savgol_filter(data,5,1)\n",
    "    #print(data_tag.shape,data.shape,smoothed_data.shape)\n",
    "    out_array = np.concatenate((data_tag,smoothed_data))\n",
    "    #print(pd.Series(out_array))\n",
    "    new_data.loc[i,:] = list(out_array)\n",
    "\n",
    "#print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
