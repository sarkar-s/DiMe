{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import copy\n",
    "from scipy.signal import savgol_filter\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "\n",
    "model_folder = current_path + '/models/linearly-growing-layers/'\n",
    "\n",
    "model = {}\n",
    "\n",
    "for i in range(1,100):\n",
    "    model[i] = keras.models.load_model(model_folder+'model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['046_CDF_survey.csv', '025_CDF_survey.csv', '048_CDF_survey.csv', '144_CDF_survey.csv', '021_CDF_survey.csv', '034_CDF_survey.csv', '137_CDF_survey.csv', '045_CDF_survey.csv', '154_CDF_survey.csv', '139_CDF_survey.csv', '001_CDF_survey.csv', '102_CDF_survey.csv', '110_CDF_survey.csv', '088_CDF_survey.csv', '013_CDF_survey.csv', '081_CDF_survey.csv', '012_CDF_survey.csv', '000_CDF_survey.csv', '017_CDF_survey.csv', '083_CDF_survey.csv', '004_CDF_survey.csv', '082_CDF_survey.csv', '072_CDF_survey.csv', '085_CDF_survey.csv']\n"
     ]
    }
   ],
   "source": [
    "data_directory = current_path + '/test_data/'\n",
    "\n",
    "os.chdir(data_directory)\n",
    "data_files = glob('*CDF_survey.csv')\n",
    "\n",
    "output_directory = current_path + '/test_data/linearly-growing-layers'\n",
    "\n",
    "print(data_files)\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_directory)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.linspace(1,99,99,dtype=int)\n",
    "quantile_names = [str(ic) for ic in c]\n",
    "\n",
    "gs = np.linspace(1,11,11,dtype=int)\n",
    "g_names = ['g'+str(i) for i in gs]\n",
    "\n",
    "column_names = ['g']+quantile_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "046_CDF_survey.csv\n",
      "(12, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 1, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#test_predictions = model[i].predict(test_data).flatten()\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     45\u001b[0m new_data[\u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(test_predictions,\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/mk/9grs11492lq8hv6sj_4yty300000gn/T/__autograph_generated_file6bh8wno4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1845, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1834, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1823, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/training.py\", line 1791, in predict_step\n        return self(x, training=False)\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/swarnavo/miniforge3/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 2), found shape=(None, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for df in data_files:\n",
    "    print(df)\n",
    "#for df in ['000_CDF_survey.csv']:\n",
    "    #a = pd.read_csv(data_directory+df,header=None).to_numpy()\n",
    "    a = pd.read_csv(data_directory+df,header=None).to_numpy()\n",
    "\n",
    "    concs = np.zeros(shape=(a.shape[0],1))\n",
    "    concs[:,0] = a[:,0]\n",
    "\n",
    "    response_labels = np.zeros(shape=(a.shape[0],a.shape[0]))\n",
    "\n",
    "    for j in range(0,a.shape[0]):\n",
    "        response_labels[j,:] = a[:,1]\n",
    "\n",
    "    #this_array = np.concatenate((concs,response_labels,a[:,1:]),axis=1)\n",
    "    mean_array = np.zeros(shape=(a[:,1].shape[0],1))\n",
    "    mean_array[:,0] = a[:,1]\n",
    "    this_array = np.concatenate((mean_array,a[:,3:-1]),axis=1)\n",
    "    #this_array = np.concatenate((concs,a[:,1:]),axis=1)\n",
    "    #print(this_array.shape)\n",
    "\n",
    "    test_data = pd.DataFrame(this_array,index=[i for i in range(a.shape[0])],columns=column_names)\n",
    "    new_data = copy.deepcopy(test_data)\n",
    "    test_labels = {}\n",
    "\n",
    "    for i in range(1,this_array.shape[1]):\n",
    "        #print(column_names[i])\n",
    "        if i==2:\n",
    "            test_labels[column_names[i]] = test_data.pop(column_names[i])\n",
    "        else:\n",
    "            test_data.pop(column_names[i])\n",
    "            \n",
    "    #model_folder = '/Users/sns9/Research/IMS_project/CytometryData/PredictDispersion/model64/'\n",
    "\n",
    "    for i in range(1,100):\n",
    "        #model = keras.models.load_model(model_folder+'model_'+str(i)+'.h5')\n",
    "        \n",
    "        print(test_data.shape)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        #test_predictions = model[i].predict(test_data).flatten()\n",
    "\n",
    "        test_predictions = model[i].predict(tf.expand_dims(test_data, axis=-1)).flatten()\n",
    "\n",
    "        new_data[str(i)] = np.maximum(test_predictions,0.0)\n",
    "        \n",
    "        if i>1:\n",
    "            test_data[str(i)] = test_data[str(i-1)] + np.maximum(test_predictions,0.0)\n",
    "        else:\n",
    "            test_data[str(i)] = np.maximum(test_predictions,0.0)\n",
    "            \n",
    "            \n",
    "        print('Layer ',i,' completed.')\n",
    "\n",
    "        #final_data = np.zeros(shape=test_predictions.shape)\n",
    "\n",
    "        \"\"\"if i>0:\n",
    "            for k in range(0,final_data.shape[0]):\n",
    "                v1 = test_predictions[k]\n",
    "                v2 = new_data[str(i-1)][k]\n",
    "                #print(v1,v2)\n",
    "                final_data[k] = max(v1,v2)\n",
    "\n",
    "            new_data[str(i)] = final_data\n",
    "\n",
    "            test_data[str(i)] = final_data\n",
    "        else:\n",
    "            new_data[str(i)] = test_predictions\n",
    "\n",
    "            test_data[str(i)] = test_predictions\n",
    "        \"\"\"\n",
    "\n",
    "    print(df,' completed.')\n",
    "    \n",
    "    #for gn in g_names:\n",
    "    #    new_data.pop(gn)\n",
    "        \n",
    "    for iq in range(1,len(quantile_names)):\n",
    "        new_data[quantile_names[iq]] += new_data[quantile_names[iq-1]]\n",
    "        \n",
    "    new_data.to_csv(output_directory+'/new_'+df,index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = pd.read_csv(data_file,header=None).to_numpy()\n",
    "\n",
    "concs = np.zeros(shape=(a.shape[0],1))\n",
    "concs[:,0] = a[:,0]\n",
    "\n",
    "response_labels = np.zeros(shape=(a.shape[0],a.shape[0]))\n",
    "\n",
    "for j in range(0,a.shape[0]):\n",
    "    response_labels[j,:] = a[:,1]\n",
    "    \n",
    "this_array = np.concatenate((concs,response_labels,a[:,1:]),axis=1)\n",
    "#print(this_array.shape)\n",
    "\n",
    "test_data = pd.DataFrame(this_array,index=[i for i in range(a.shape[0])],columns=column_names)\n",
    "new_data = copy.deepcopy(test_data)\n",
    "test_labels = {}\n",
    "\n",
    "for i in range(13,this_array.shape[1]):\n",
    "    #print(column_names[i])\n",
    "    if i==2:\n",
    "        test_labels[column_names[i]] = test_data.pop(column_names[i])\n",
    "    else:\n",
    "        test_data.pop(column_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_folder = '/Users/sns9/Research/IMS_project/CytometryData/PredictDispersion/model64/'\n",
    "\n",
    "for i in range(0,101):\n",
    "    model = keras.models.load_model(model_folder+'model_'+str(i)+'.h5')\n",
    "    \n",
    "    test_predictions = model.predict(test_data).flatten()\n",
    "    \n",
    "    new_data[str(i)] = test_predictions\n",
    "    \n",
    "    test_data[str(i)] = test_predictions\n",
    "    \n",
    "    final_data = np.zeros(shape=test_predictions.shape)\n",
    "    \n",
    "    \"\"\"if i>0:\n",
    "        for k in range(0,final_data.shape[0]):\n",
    "            v1 = test_predictions[k]\n",
    "            v2 = new_data[str(i-1)][k]\n",
    "            #print(v1,v2)\n",
    "            final_data[k] = max(v1,v2)\n",
    "            \n",
    "        new_data[str(i)] = final_data\n",
    "    \n",
    "        test_data[str(i)] = final_data\n",
    "    else:\n",
    "        new_data[str(i)] = test_predictions\n",
    "    \n",
    "        test_data[str(i)] = test_predictions\n",
    "    \"\"\"\n",
    "    \n",
    "print(df,' completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for gn in g_names:\n",
    "    new_data.pop(gn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for iq in range(1,len(quantile_names)):\n",
    "    #print(quantile_names[iq-1],quantile_names[iq])\n",
    "    new_data[quantile_names[iq]] += new_data[quantile_names[iq-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_data.to_csv('new_'+data_file,index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in new_data.index:\n",
    "    data_tag = new_data.loc[i].to_numpy()[:2]\n",
    "    data = new_data.loc[i].to_numpy()[2:]\n",
    "    smoothed_data = savgol_filter(data,5,1)\n",
    "    #print(data_tag.shape,data.shape,smoothed_data.shape)\n",
    "    out_array = np.concatenate((data_tag,smoothed_data))\n",
    "    #print(pd.Series(out_array))\n",
    "    new_data.loc[i,:] = list(out_array)\n",
    "\n",
    "#print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
